---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

<style> .indented { padding-left: 50pt; padding-right: 50pt; } </style>

<p>My research centres on philosophical questions surrounding the dynamics of complex social systems using formal tools from evolutionary game theory. This research involves interrelated projects which address (1) the social, philosophical, legal, and ethical implications of artificial intelligence, machine learning, and other data-driven technologies, (2) the evolutionary origins of linguistic communication, and (3) the dynamics of other, non-linguistic, social phenomena. Some current research projects of mine are described below.</p>
   
<h3> 1. Philosophy and Ethics of AI and Emerging Technologies.</h3> 

<p>A significant focus of my interdisciplinary research concerns the ethical, social, legal, and philosophical implications of artificial intelligence (AI) and emerging technologies. This work is unified by questions surrounding ethically aligned learning machines, or how AI systems can acquire moral competence. For example, 
<ul>
   <li><i> What is the nature of moral agency, such that it could be attributed to artificial systems?</i></li> 
   <li><i>How can we ensure that the objectives (value functions) of an AI system align with the values of human agents, individually and collectively?</i></li> 
   <li><i>How can insights from research on value alignment be applied to complex human systems?</i></li> 
   <li><i>What cooperative challenges do AI researchers face for adhering to agreed-upon conventions to ensure safe research? </i></li>
</ul> 
These questions are important in the long-term for AI safety, toward building machines which can achieve specific goals while acting in a way that is consistent with human values and social norms.</p>

<h3>2. Evolutionary Origins of Linguistic Communication.</h3>

<p>This work aims to address the following questions: 
<ul>
   <li><i>What are the salient differences between the simple signalling systems that are ubiquitous in nature and the linguistic communication systems that are unique to humans?</i> Further,</li> 
   <li><i>Which of these salient features of natural language provides an empirically plausible target for explaining how linguistic communication systems may have evolved out of simpler systems of communication?</i></li>
</ul> 
Many researchers think that if we could explain how some distinctive feature(s) of language evolved, we would have taken great strides in bridging the evolutionary gap between simple communication and natural language. The most common feature of natural language that is appealed to as a gap-bridging explanatory target is compositionality (and related features like hierarchy and recursion). I argue that the emphasis placed on compositional syntax in language-origins research is misguided. This suggests that it is a mistake to assume that since compositional syntax provides a crucial difference between language and simple communication, research on language origins must, therefore, centre on the evolution of compositional syntax itself.</p> 

<p> Instead, I propose that reflexivity—the ability to use language to talk about language—provides a plausible alternative explanatory target for language-origins research. Communication is a unique evolved mechanism to the extent that it can overtly influence the evolution of future communication: once individuals learn to communicate, those abilities may be used to influence future communicative behaviour, leading to a positive feedback loop. Furthermore, reflexivity gives rise to rich compositional structures from which genuinely compositional syntax can emerge—but, as a byproduct rather than an explicit target of evolutionary pressures. Finally, I further argue that reflexivity does not succumb to the problems that compositionality faces: role asymmetries are accounted for by the underlying mechanisms that give rise to reflexive communication systems; there exists empirical evidence of plausible precursors to reflexivity in nature; and, the precursors of reflexivity are genuinely graded. This furnishes a novel (and plausible) account of how language might have evolved out of simpler non-linguistic precursors.
</p>

<h3>3. Social Dynamics, Epistemology, and Justice.</h3> 

<p>I am also interested in the dynamics of (non-linguistic) social phenomena more generally. This research stems primarily from work done under a grant from the National Science Foundation (USA) on <i>Social Dynamics and Diversity in Epistemic Communities</i> (PI:  <a href="http://cailinoconnor.com" title="Cailin, not Caitlin">Cailin O’Connor</a>, UC Irvine). We use formal models and simulation results to make arguments about a variety of social phenomena. For example, our work on discrimination shows how small degrees of power give rise to radically inequitable distributions of resources between perceptibly distinct, but otherwise effectively identical, populations of individuals. This result has consequences for the viability of accounts of distributive justice. Our work (with <a href="https://www.linkedin.com/in/andersgeil" title="Anders Geil">Anders Geil</a>, Columbia University) in social epistemology shows how false beliefs—concerning, for example, scientific information or ‘fake news’ items—spread and persist in a network of individuals, even when an explicit retraction is issued. This research programme is unified by the aim of understanding the role of social structure and interaction on epistemology and justice. </p>
   
<p>Outside of this central field of study, I have additional research interests in philosophy of language (more traditionally construed) and metasemantics; social, political, and legal philosophy; and 20th Century analytic philosophy—especially Frege, Russell, and Wittgenstein.</p>

<h2>Dissertation</h2>

<details>
   <summary><a> <strong> Complex Signals: Reflexivity, Hierarchical Structure, and Modular Composition </strong></a></summary>
   <div class="indented">
      <p>
         My dissertation argues that what drives the emergence of complex communication systems is a process of modular composition, whereby independent communicative dispositions combine to create more complex dispositions. This challenges the dominant view on the evolution of language, which attempts to resolve the explanatory gap between communication and language by demonstrating how complex syntax evolved. My research shows that these accounts fail to maintain sensitivity to empirical data: genuinely compositional syntax is extremely rare or non-existent in nature. In contrast, my research prioritises the reflexivity of natural language—the ability to use language to talk about language—as an alternative explanatory target. 
      </p>
      <p>
         The first part of my dissertation provides the philosophical foundation of this novel account using the theoretical framework of Lewis-Skyrms signalling games and drawing upon relevant work in evolutionary biology, linguistics, cognitive systems, and machine learning. Chapter 1 introduces the signalling game and contextualises it with respect to problems in the realm of traditional philosophy of language. Chapter 2 examines empirical data from biology and linguistics and argues that complex syntax is not the most apt explanatory target for how language might have evolved out of simple communication. Chapter 3 then argues that the reflexivity of language is a more fruitful property to consider, showing how reflexivity aids the evolution of complex communication via a process of modular composition. This connects parallel research in the evolution of language, cognitive systems, and machine learning paradigms. Once such complexity is exhibited, at a small scale, it may lead to a 'feedback loop' between communication and cognition that gives rise to the complexity we see in natural language.
      </p>
         The second part of my dissertation provides a set of models, along with analytic and simulation results, that show precisely how (and under what circumstances) this process of modular composition is supposed to work.
      </p>
   <p>
         A more detailed summary of this work can be read <a href="https://travislacroix.github.io/files/ND-Dissertation-Summary.pdf" title="Dissertation Summary"> HERE.</a>
   </p>
   <p>
         <a href="https://escholarship.org/uc/item/5328x080" title="Complex Signals">[Official version available here.]</a><br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2020. Complex Signals: Reflexivity, Hierarchical Structure, and Modular Composition. <i>UC Irvine</i>. ProQuest ID: LaCroix_uci_0030D_16213. Merritt ID: ark:/13030/m5ps345j. Retrieved from https://escholarship.org/uc/item/5328x080<br>
      </p>
   </div>
</details>

<h2>Published Articles</h2>

<details>
   <summary><a> <strong> Est-ce que vous Compute? Code-Switching, Culutral Identity, and AI </strong> (with Arianna Falbo) <br> <p style="text-indent: 20pt"><i>Feminist Philosophical Quarterly</i></p></a> </summary>
   <div class="indented">
      <p>
         Cultural code-switching concerns how we adjust our overall behaviours, manners of speaking, and appearance in response to a perceived change in our social environment. We defend the need to investigate cultural code-switching capacities in artificial intelligence systems. We explore a series of ethical and epistemic issues that arise when bringing cultural code-switching to bear on artificial intelligence. Building upon Dotson's (2014) analysis of testimonial smothering, we discuss how emerging technologies in AI can give rise to epistemic oppression, and specifically, a form of self-silencing that we call 'cultural smothering'. By leaving the socio-dynamic features of cultural code-switching unaddressed, AI systems risk negatively impacting already-marginalised social groups by widening opportunity gaps and further entrenching social inequalities.
      </p>
      <p>
         <a href="https://arxiv.org/abs/2112.08256" title="Est-ce que vous compute, Pre-print">[arXiv Pre-print Available Here.]</a> (Please cite published version, if available.)<br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> Falbo, Arianna and Travis LaCroix. 2022. "Est-ce que vous compute? Code-switching, cultural identity and AI." <i>Feminist Philosophical Quarterly</i>. (Forthcoming).<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Moral Dilemmas for Moral Machines </strong> <br> <p style="text-indent: 20pt"><i>AI and Ethics</i></p></a> </summary>
   <div class="indented">
      <p>
         Autonomous systems are being developed and deployed in situations that may require some degree of ethical decision-making ability. As a result, research in machine ethics has proliferated in recent years. This work has included using moral dilemmas as validation mechanisms for implementing decision-making algorithms in ethically-loaded situations. Using trolley-style problems in the context of autonomous vehicles as a case study, I argue (1) that this is a misapplication of philosophical thought experiments because (2) it fails to appreciate the purpose of moral dilemmas, and (3) this has potentially catastrophic consequences; however, (4) there are uses of moral dilemmas in machine ethics that are appropriate and the novel situations that arise in a machine-learning context can shed some light on philosophical work in ethics.
      </p>
      <p>
         <a href="https://rdcu.be/cIMmt" title="Moral dilemmas for moral machines, Official">[Official version available here.]</a> <br>

         <a href="http://philsci-archive.pitt.edu/20339/" title="Moral dilemmas for moral machines, Pre-print">[Phil-Sci Archive Pre-print.]</a> (Please cite published version, if available.)<br>
         
         <a href="https://arxiv.org/abs/2203.06152" title="Moral dilemmas for moral machines, Pre-print">[arXiv Pre-print.]</a> (Please cite published version, if available.)<br>

      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2022. "Moral dilemmas for moral machines." <i>AI and Ethics</i>. (Forthcoming). <a href="https://doi.org/10.1007/s43681-022-00134-y">[https://doi.org/10.1007/s43681-022-00134-y]</a>.<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong>Reflexivity, Functional Reference, and Modularity: Alternative Targets for Language Origins</strong> <br> <p style="text-indent: 20pt"><i>Philosophy of Science</i></p></a> </summary>
   <div class="indented">
      <p>
         Researchers in language origins typically try to explain how compositional communication might evolve to bridge the gap between animal communication and natural language. However, as an explanatory target, compositionality has been shown to be problematic for a gradualist approach to the evolution of language.  In this paper, I suggest that <i>reflexivity</i> provides an apt and plausible alternative target which does not succumb to the problems that compositionality faces. I further explain how <i>proto</i>-reflexivity, which depends upon functional reference, gives rise to complex communication systems via modular composition.
      <p>
         <a href="https://doi.org/10.1086/715217" title="Reflexivity, Functional Reference, and Modularity, Official">[Official Version Available Here.]</a><br>

         <a href="http://philsci-archive.pitt.edu/19797/" title="Reflexivity, Functional Reference, and Modularity, Pre-Print">[PhilSci Archive Pre-print Available Here.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2020. "Reflexivity, Functional Reference, and Modularity: Alternative Targets for Language Origins." <i>Philosophy of Science</i> (2021) 8(5): 1234-1245.<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Power by Association </strong> (with Cailin O'Connor) <br> <p style="text-indent: 20pt"><i>Ergo, an Open Access Journal of Philosophy</i></p></a> </summary>
   <div class="indented">
      <p>
         We use tools from evolutionary game theory to examine how power might influence the cultural evolution of inequitable norms between discernible groups (such as gender or racial groups) in a population of otherwise identical individuals. Similar extant models always assume that power is homogeneous across a social group. As such, these models fail to capture situations where individuals who are not themselves disempowered nonetheless end up disadvantaged in bargaining scenarios by dint of their social group membership. Thus, we assume that there is heterogeneity in the groups in that some individuals are more powerful than others.
      </p>
      <p>
         Our model shows that even when most individuals in two discernible sub-groups are relevantly identical, powerful individuals can affect the social outcomes for their entire group; this results in power by association for their in-group and a bargaining disadvantage for their out-group. In addition, we observe scenarios like those described where individuals who are more powerful will get less in a bargaining scenario because a convention has emerged disadvantaging their social group.
      </p>
      <p>
         <a href="http://philsci-archive.pitt.edu/14318/" title="Power by Association, Draft">[PhilSci Archive Pre-print Available Here.]</a> (Please cite published version, if available.)<br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis and Cailin O'Connor. 2021. "Power by Association." <i>Ergo</i>. (Forthcoming).<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Emergent Communication under Competition </strong> (with Michael Noukhovitch, Angeliki Lazaridou, and Aaron Courville) <br> <p style="text-indent: 20pt"><i>Autonomous Agents and Multiagent Systems (AAMAS 2021)</i></p></a> </summary>
   <div class="indented">
      <p>
         Current literature in machine learning has only negative results for learning to communicate between competitive agents using vanilla RL. We introduce a modified sender-receiver game to study the spectrum of partially-competitive scenarios and show communication can indeed emerge in this setting. We empirically demonstrate three key takeaways for future research. First, we show that communication is proportional to cooperation, and it can occur for partially competitive scenarios using standard learning algorithms. Second, we highlight the difference between communication and manipulation and extend previous metrics of communication to the competitive case. Third, we investigate the negotiation game where previous work failed to learn communication between independent agents. We show that, in this setting, both agents must benefit from communication for it to emerge. Finally, with a slight modification to the game, we successfully learn to communicate between competitive agents. We hope this work overturns misconceptions and inspires more research in competitive emergent communication.
      </p>
            <p>
         <a href="https://dl.acm.org/doi/10.5555/3463952.3464066" title="Emergent Communication, Official">[Official Version Available Here.]</a><br>

         <a href="https://arxiv.org/abs/2101.10276" title="Emergent Communication, Pre-Print">[arXiv Pre-print Available Here.]</a> (Please cite published version, if available.)<br>
               
         <a href="https://slideslive.com/38954927/emergent-communication-under-competition" title="Recorded Talk, SlidesLive">[Recorded Talk (Noukhovitch) Available Here.]</a> <br>
      </p>
            <p>
         <b>Recommended citation</b>: <br>Noukhovitch, Michael, Travis LaCroix, Angeliki Lazaridou, and Aaron Courville. 2021. Emergent Communication under Competition. In U. Endriss, A. Nowé, F. Dignum, and A. Lomuscio (eds.), <i>Proc. of the 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2021)</i>, London, UK, 3-7 May 2021, International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS) 974-982.<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> The Dynamics of Retraction in Epistemic Networks </strong> (with Cailin O'Connor and Anders Geil) <br> <p style="text-indent: 20pt"><i>Philosophy of Science</i></p></a> </summary>
   <div class="indented">
      <p>
         Sometimes retracted scientific information is used and propagated long after it is understood to be misleading.  Likewise, sometimes retracted news items spread and persist, even after it has been publicly established that they are false.  In this paper, we use agent-based models of epistemic networks to explore the dynamics of retraction.  In particular we focus on why false beliefs might persist, even in the face of retraction.
      </p>
      <p>
         <a href="https://doi.org/10.1086/712817" title="Dynamics of Retraction, Official">[Official Version Available Here.]</a><br>
         <a href="http://philsci-archive.pitt.edu/17088/" title="Dynamics of Retraction, Draft">[PhilSci Archive Pre-print Available Here.]</a> (Please cite published version, if available.)<br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis, Anders Geil, and Cailin O'Connor. 2020. "The Dynamics of Retraction in Epistemic Networks." <i>Philosophy of Science</i> (2021) 88(3): 415-438.<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Epistemology and the Structure of Language </strong> (with Jeffrey A. Barrett) <br> <p style="text-indent: 20pt"><i>Erkenntnis</i></p></a> </summary>

   </summary>
   <div class="indented">
      <p>
         We are concerned here with how structural properties of language may evolve to reflect features of the world in which it evolves. As a concrete example, we will consider how a simple term language might evolve to support the principle of indifference over state descriptions in that language. The point is not that one is justified in applying the principle of indifference to state descriptions in natural language. Rather, it is that one should expect a language that has evolved in the context of facilitating successful action to reflect probabilistic features of the world in which it evolved.
      <br> </p>
         <p>
         <a href="https://doi.org/10.1007/s10670-020-00225-4" title="Epistemology and the Structure of Language, Erkenntnis">[Official Version Available Here.]</a> <br>
         <a href="http://philsci-archive.pitt.edu/16986/" title="Epistemology and the Structure of Language, Pre-Print">[PhilSci Archive Pre-print Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> Barrett, Jeffrey A. and Travis LaCroix. 2020. "Epistemology and the Structure of Language." <i>Erkenntnis</i>. Forthcoming.<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Communicative Bottlenecks Lead to Maximal Information Transfer </strong> <br> <p style="text-indent: 20pt"><i>Journal of Experimental and Theoretical Artificial Intelligence</i></p></a> </summary>

   </summary>
   <div class="indented">
      <p>
         This paper presents new analytic and numerical analysis of signalling games that give rise to informational bottlenecks—that is to say, signalling games with more state/act pairs than available signals to communicate information about the world. I show via simulation that agents learning to coordinate tend to favour partitions of nature which provide maximal information transfer. This is true in spite of the fact that nothing from an initial analysis of the stability properties of the underlying signalling game suggests that this should be the case. As a first pass to explain this, I note that the underlying structure of our model favours maximal information transfer in regard to the simple combinatorial properties of the ways in which the agents might partition nature into kinds. However, I suggest that this does not perfectly capture the empirical results; thus, several open questions remain.
      </p>
      <p>
         <a href="http://dx.doi.org/10.1080/0952813X.2020.1716857" title="Communicative Bottlenecks, Official">[Official Version Available Here.]</a>
      <br>
         <a href="http://philsci-archive.pitt.edu/16843/" title="Communicative Bottlenecks, Pre-Print">[PhilSci Archive Pre-print Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br>LaCroix, Travis. 2020. "Communicative Bottlenecks Lead to Maximal Information Transfer." <i>Journal of Experimental and Theoretical Artificial Intelligence</i> (2020) 32(6): 997-1014.<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Using Logic to Evolve More Logic: Composing Logical Operators via Self-Assembly </strong> <br> <p style="text-indent: 20pt"><i>British Journal for the Philosophy of Science</i></p></a> </summary>

   </summary>
   <div class="indented">
      <p>
         I consider how complex logical operations might self-assemble in a signalling-game context via composition of simpler underlying dispositions. On the one hand, agents may take advantage of pre-evolved dispositions; on the other hand, they may co-evolve dispositions as they simultaneously learn to combine them to display more complex behaviour. In either case, the evolution of complex logical operations can be more efficient that evolving such capacities from scratch. Showing how complex phenomena like these might evolve provides an additional path to the possibility of evolving more or less rich notions of compositionality. This helps provide another facet of the evolutionary story of how sufficiently rich, human-level cognitive or linguistic capacities may arise from simpler precursors.
         <br> </p>
         <p>
         <a href="https://doi.org/10.1093/bjps/axz049" title="Using Logic to Evolve More Logic, BJPS">[Official Version Available Here.]</a> <br>
         <a href="http://philsci-archive.pitt.edu/16658/" title="Using Logic to Evolve More Logic, Pre-Print">[PhilSci Archive Pre-print Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2019. "Using Logic to Evolve More Logic: Composing Logical Operators via Self-Assembly." <i>British Journal for the Philosophy of Science</i>. Forthcoming. <br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Biology and Compositionality: Empirical Considerations for Emergent-Communication Protocols </strong> <br> <p style="text-indent: 20pt"><i>NeurIPS 2019 workshop Emergent Communication: Towards Natural Language</i></p></a> </summary>

   </summary>
   <div class="indented">
      <p>
         Significant advances have been made in artificial systems by using biological systems as a guide. However, there is often little interaction between computational models for emergent communication and biological models of the emergence of language. Many researchers in language origins and emergent communication take compositionality as their primary target for explaining how simple communication systems can become more like natural language. However, there is reason to think that compositionality is the wrong target on the biological side, and so too the wrong target on the machine-learning side. As such, the purpose of this paper is to explore this claim. This has theoretical implications for language origins research more generally, but the focus here will be the implications for research on emergent communication in computer science and machine learning—specifically regarding the types of programmes that might be expected to work and those which will not. I further suggest an alternative approach for future research which focuses on reflexivity, rather than compositionality, as a target for explaining how simple communication systems may become more like natural language. I end by providing some reference to the language origins literature that may be of some use to researchers in machine learning.
         <br> </p>
         <p>
         <a href="https://arxiv.org/abs/1911.11668" title="Biology and Compositionality, ArXiv">[ArXiv Pre-print Available Here.]</a> <br>
         <a href="http://travislacroix.github.io/files/LaCroix-NeurIPS-Poster-33x46-Biology-and-Compositionality.pdf" title="Biology and Compositionality, Poster">[Poster Available Here.]</a> <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2019. "Biology and Compositionality: Empirical Considerations for Emergent-Communication Protocols." <i>arxiv.org/abs/1911.11668</i>. <br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Evolutionary Explanations of Simple Communication: Signalling Games &amp; Their Models </strong> <br> <p style="text-indent: 20pt"><i>Journal for General Philosophy of Science / Zeitschrift f&uuml;r allgemeine Wissenschaftstheorie</i></p></a> </summary>
   <div class="indented">
      <p>         
         This paper applies the theoretical criteria laid out by D'arms et al. (1998) to various aspects of evolutionary models of signalling. The question that D'Arms et al. seek to answer can be formulated as follows: Are the models that we use to explain the phenomena in question conceptually adequate? The conceptual adequacy question relates the formal aspects of the model to those aspects of the natural world that the model is supposed to capture. Moreover, this paper extends the analysis of D'Arms et al. by asking the following additional question: Are the models that we use sufficient to explain the phenomena in question? The sufficiency question ask what formal resources are minimally required in order for the model to get the right results most of the time.
      </p>
      <p>
         <a href="https://doi.org/10.1007/s10838-019-09481-7" title="Evolutionary Explanations of Simple Communication, JGPS">[Official Version Available Here.]</a><br>
         <a href="http://philsci-archive.pitt.edu/16604/" title="Evolutionary Explanations of Simple Communication, Pre-Print">[PhilSci Archive Pre-print Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2019. "Evolutionary Explanations of Simple Communication: Signalling Games &amp; Their Models." <i>Journal for General Philosophy of Science / Zeitschrift f&uuml;r allgemeine Wissenschaftstheorie</i> (2020) 51(1): 19-43.<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> On Salience and Signalling in Sender-Receiver Games: Partial-Pooling, Learning, and Focal Points </strong> <br> <p style="text-indent: 20pt"><i>Synthese</i></p></a> </summary>
   <div class="indented">
      <p>
         I introduce an extension of the Lewis-Skyrms signaling game, analysed from a dynamical perspective via simple reinforcement learning. In Lewis' (Convention, Blackwell, Oxford, 1969) conception of a signaling game, salience is offered as an explanation for how individuals may come to agree upon a linguistic convention. Skyrms (Signals: evolution, learning & information, Oxford University Press, Oxford, 2010a) offers a dynamic explanation of how signaling conventions might arise presupposing no salience whatsoever. The extension of the atomic signaling game examined here—which I refer to as a <i>salience game</i>—introduces a variable parameter into the atomic signaling game which allows for degrees of salience, thus filling in the continuum between Skyrms' and Lewis' models. The model does not presuppose any salience at the outset, but illustrates a process by which accidentally evolved salience is amplified, to the benefit of the players. It is shown that increasing degrees of salience allow populations to avoid sub-optimal pooling equilibria and to coordinate upon conventions more quickly. <br>
      </p>
      <p>
         <a href="https://doi.org/10.1007/s11229-018-1766-z" title="Salience and Signaling, Synthese">[Official Version Available Here.]</a><br>
         <a href="http://philsci-archive.pitt.edu/16270/" title="Salience and Signaling, Pre-Print">[PhilSci Archive Pre-print Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2018. "On Salience and Signaling in Sender-Receiver Games: Partial Pooling, Learning, and Focal Points." <i>Synthese</i> (2020) 197(4): 1725-1747. <br>
      </p>
      </div>
</details>

<h2>Under Review</h2>

<details>
   <summary><a> <strong> Accounting for Polysemy and Role Asymmetry in the Evolution of Compositional Signals </strong></a> </summary>
   <div class="indented">
      <p>
         Several formal models of signalling conventions have been proposed to explain how and under what circumstances compositional signalling might evolve. I suggest that these models fail to give a plausible account of the evolution of compositionality because (1) they apparently take <i>linguistic</i> compositionality as their target phenomenon, and (2) they are insensitive to role asymmetries inherent to the signalling game. I further suggest that, rather than asking how signals might come to be compositional, we must clarify what it would mean for signals to <i>be</i> compositional to begin with.
 <br>
      </p>
      <p>
         <a href="https://travislacroix.github.io/files/ND-Polysemy-and-Role-Asymmetry.pdf" title="Polysemy and Role Asymmetry, Draft">[Unpublished Draft Available Here.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2019. "Accounting for Polysemy and Role-Asymmetry in the Evolution of Compositional Signals." <i>Unpublished Manuscript</i>. May 2019, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> The Correction Game or, How Pre-Evolved Communicative Dispositions Might Affect Communicative Dispositions </strong></a> </summary>
   <div class="indented">
      <p>
         How might pre-evolved communicative dispositions affect how individuals learn to communicate in a novel context? I present a model of learning that varies the reward for coordination in the signalling game framework under simple reinforcement learning as a function of the agents' actions. The model takes advantage of a type of modular compositional communicative bootstrapping by which the sender and receiver use pre-evolved communicative dispositions—a "yes/no" command—to evolve new dispositions.
 <br>
      </p>
      <p>
         <a href="https://travislacroix.github.io/files/ND-Correction-Game.pdf" title="Correction Game, Draft">[Unpublished Draft Available Here.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2019. "The Correction Game or, How Pre-Evolved Communicative Dispositions Might Affect Communicative Dispositions." <i>Unpublished Manuscript</i>. April 2019, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> Information and Meaning in the Evolution of Compositional Signals </strong></a> </summary>
   <div class="indented">
      <p>
      This paper provides a formal treatment of the argument that syntax alone cannot give rise to compositionality in a signalling game context. This conclusion follows from the standard information-theoretic machinery used in the signalling game literature to describe the informational <i>content</i> of signals.  
      <br>
      </p>
      <p>
         <a href="" title="Information and Meaning in the Evolution of Compositional Signals, Draft">[Pre-print available soon.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2022. "Information and Meaning in the Evolution of Compositional Signals." <i>Unpublished Manuscript</i>. April 2022.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> Learning From Learning Machines: Optimisation, Rules, and Social Norms </strong> (with Yoshua Bengio) </a> </summary>
   <div class="indented">
      <p>
         There is an analogy between machine learning systems and economic entities in that they are both adaptive, and their behaviour is specified in a more or less explicit way. It appears that the area of AI that is most analogous to the behaviour of economic entities is that of <i>morally good decision-making</i>, but it is an open question as to how precisely moral behaviour can be achieved in an AI system. This paper explores the analogy between these two complex systems, and we suggest that a clearer understanding of this apparent analogy may help us forward in both the socio-economic domain and the AI domain: known results in economics may help inform feasible solutions in AI safety, but also known results in AI may inform economic policy. If this claim is correct, then the recent successes of deep learning for AI suggest that more <i>implicit</i> specifications work better than explicit ones for solving such problems. 
      </p>
      <p>
         <a href="https://arxiv.org/abs/2001.00006" title="Learning from Learning Machines, Draft">[arXiv Pre-Print Available Here.]</a> (Please cite published version, if available.)<br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis and Yoshua Bengio. 2019. "Learning from Learning Machines: Optimisation, Rules, and Social Norms." <i>arxiv.org/abs/2001.00006</i>.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> The Linguistic Blind Spot of Value-Aligned Agency, Natural and Artificial </strong> </a> </summary>
   <div class="indented">
      <p>
         The value-alignment problem for artificial intelligence (AI) asks how we can ensure that the 'values'—i.e., objective functions—of artificial systems are aligned with the values of humanity. In this paper, I argue that linguistic communication is a necessary condition for robust value alignment. I discuss the consequences this the truth of this claim would have for research programmes that attempt to ensure value alignment for AI systems—or, more loftily, designing robustly beneficial or ethical artificial <i>agents</i>. 
      </p>
      <p>
         <a href="" title="Linguistic Blind Spot, Draft">[Pre-print available soon.]</a> (Please cite published version, if available.)<br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2022. "The linguistic blind spot of value-aligned agency, natural and artificial." <i>Unpublished Manuscript</i>. February 2022.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> Metaethical Perspectives on 'Benchmarking' AI Ethics </strong> (with Alexandra Sasha Luccioni)</a> </summary>
   <div class="indented">
      <p>
         Benchmarks are seen as the cornerstone for measuring technical progress in Artificial Intelligence (AI) research and have been developed for a variety of tasks ranging from question answering to facial recognition. An increasingly prominent research area in AI is ethics, which currently has no set of benchmarks nor commonly accepted way for measuring the 'ethicality' of an AI system. In this paper, drawing upon research in moral philosophy and metaethics, we argue that it is impossible to develop such a benchmark. As such, alternative mechanisms are necessary for evaluating whether an AI system is 'ethical'. This is especially pressing in light of the prevalence of applied, industrial AI research. We argue that it makes more sense to talk about 'values' (and 'value alignment') rather than 'ethics' when considering the possible actions of present and future AI systems. We further highlight that, because values are unambiguously relative, focusing on values forces us to consider explicitly <i>what</i> the values are and <i>whose</i> values they are. Shifting the emphasis from ethics to values therefore gives rise to several new ways of understanding how researchers might advance research programmes for robustly safe or beneficial AI. We conclude by highlighting a number of possible ways forward for the field as a whole, and we advocate for different approaches towards more value-aligned AI research.
 <br>
      </p>
      <p>
         <a href="" title="Metaethical perspective on benchmarking AI ethics, Draft">[Pre-print available soon.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis and Alexandra Sasha Luccioni. 2022. "Metaethical Perspectives on ‘Benchmarking’ AI Ethics." <i>Unpublished Manuscript</i>. February 2022.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> The Tragedy of the AI Commons </strong> (with Aydin Mohseni) </a> </summary>
   <div class="indented">
      <p>
         Policy and guideline proposals for ethical artificial-intelligence research have proliferated in recent years. These are supposed to guide the socially-responsible development of AI for the common good. However, there typically exist incentives for non-cooperation (i.e., non-adherence to such policies and guidelines); and, these proposals often lack effective mechanisms to enforce their own normative claims. The situation just described constitutes a social dilemma—namely, a situation where no one has an individual incentive to cooperate, though mutual cooperation would lead to the best outcome for all involved. In this paper, we use stochastic evolutionary game dynamics to model this social dilemma in the context of the ethical development of artificial intelligence. This formalism allows us to isolate variables that may be intervened upon, thus providing actionable suggestions for increased cooperation amongst numerous stakeholders in AI. Our results show how stochastic effects can help make cooperation viable in such a scenario. They suggest that coordination for a common good should be attempted in smaller groups in which the cost for cooperation is low, and the perceived risk of failure is high. This provides insight into the conditions under which we should expect such ethics proposals to be successful with regard to their scope, scale, and content.
 <br>
      </p>
      <p>
         <a href="https://arxiv.org/abs/2006.05203" title="Tragedy of the AI Commons, Draft">[arXiv Pre-Print Available Here.]</a> (Please cite official version, if available.) <br>
         <a href="https://player.vimeo.com/video/505335066?h=4403910eed" title="Recorded Talk, Vimeo">[Recorded Talk Available Here.]</a> <br>
         <a href="https://travislacroix.github.io/files/LaCroix-Mohseni-PSA-Poster-Final-36x48.pdf" title="Tragedy of the AI Commons, Poster">[Poster Available Here.]</a>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis and Aydin Mohseni. 2020. "The Tragedy of the AI Commons." <i>Unpublished Manuscript</i>. June 2020, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> What Russell Can Denote: Aboutness and Denotation Between <i>Principles</i> and 'On Denoting' </strong></a> </summary>
   <div class="indented">
      <p>
         How ought we to analyse propositions that are about nonexistent entities? Russell (1903) details the concept of <i>denoting</i> in <i>Principles of Mathematics</i>, and this theory appears to answer the question posed. However, in the paper 'On Denoting' (Russell 1905), we see that his theory of denoting has changed greatly. Hylton (1990) argues that the move from the former theory to the latter was unnecessary. The purpose of this paper is to show that, contra Hylton, the move to the theory found in 'On Denoting' was indeed necessary.</p>
         <p>I argue that Hylton is correct to the extent that an answer to our first question relies on a different question concerning the ontology of nonexistent entities. However, this fails to take into account is a more interesting question regarding the truth values of propositions containing such puzzling entities. This question relies on Russell's notion of aboutness, and in this sense is more sensitive to his theory as a complete picture of denotation. If we take the aboutness relation seriously, then we see that the move from the former theory to the latter was necessary after all.<br>
      </p>
      <p>
         <a href="https://travislacroix.github.io/files/ND-What-Russell-Can-Denote.pdf" title="What Russell Can Denote, Draft">[Unpublished Draft Available Here.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. 2019. "What Russell Can Denote: Aboutness and Denotation Between <i>Principles</i> and 'On Denoting'." <i>Unpublished Manuscript</i>. May 2019, PDF File.<br>
      </p>
   </div>
</details>

<h2>Selected Working Papers</h2>

<details>
   <summary><a> <strong> Reference by Proxy and Truth-in-a-Model </strong> </a> </summary>
   <div class="indented">
      <p>
         Simchen (2017) brings to light the notion of 'scrambled truth' to show how productivist metasemantics is able to deal with problems of singular reference in a way that an interpretationist metasemantics (such as Lewisian reference magnetism) cannot. This serves to show that productivism is a live alternative, and indeed a rival to interpretationist metasemantics, and so cannot be subsumed by interpretationist theories.
      </p>
      <p>
         I examine Simchen's challenge to interpretationist metasemantics by extending his theoretical problem in light of actual communicative exchanges. I show that when the problem is couched in these terms, the ability to refer depends inherently upon coordination—the onus of which is on the receiver. Thus, I show how the interpretationist stance, in this case, can reasonably be understood to encompass the productivist stance.
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> Saltationist versus Gradualist Approaches to Language Origins: A Critical Discussion </strong> </a> </summary>
   <div class="indented">
      <p>
         In spite of their vast differences, theories of language origins can be, more or less, partitioned into two exhaustive and mutually exclusive camps: <i>saltationist</i> and <i>gradualist</i>. Saltationism—from the Latin <i>saltus</i>, meaning 'leap'—is the view that (the human-level capacity for) language sprang into existence suddenly and recently, and that there is a complete discontinuity between the linguistic capacities of humans and the communication systems of non-human animals; whereas, gradualism—from the Latin <i>gradus</i>, meaning 'step'—is the view that language evolved slowly over long periods of time. However, rather than arguing for the plausibility of a gradualist versus a saltationist scenario, most researchers appear to fall into one or the other camp based purely upon external or pre-theoretic commitments regarding what they believe evolved [emerged] and how.
      </p>
      <p>
         The purpose of this paper is to critically survey the respective commitments and entailments of saltationist and gradualist theories of language origins in order to make an explicit argument that the saltationist view is theoretically untenable. Under scrutiny, holding one or the other theoretical stance toward language origins will require or entail certain commitments, which vary in plausibility. It appears that many researchers either ignore these facts or are willing to bite the bullet with respect to them. However, arguments for why one should be so willing are often few and far between.
      </p>
   </div>
</details>

<br>


