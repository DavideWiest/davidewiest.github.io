---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

<style> .indented { padding-left: 50pt; padding-right: 50pt; } </style>

<p>My research centres on philosophical questions surrounding the biological and cultural evolution of complex social-dynamical systems using formal tools from evolutionary game theory. I specifically apply these methods to two defined research programmes.</p>
   
<p>The first focuses on the evolution of language. I investigate game-theoretic and evolutionary models for the emergence of complex communication in a way that is sensitive to biological, linguistic, and cognitive constraints. This work draws upon diverse fields, including philosophy of science, cognitive systems, evolutionary biology, linguistics, and machine learning. I have also explored the evolution of dynamic social phenomena more generally. My research on discrimination shows how small degrees of power give rise to radically inequitable distributions of resources between perceptibly distinct (though effectively identical) social groups—this result has consequences for the viability of accounts of distributive justice. My research in social epistemology shows how false beliefs spread and persist in a network, even when an explicit retraction is issued. </p>   

<p>The second focuses on AI safety and the ethical, social, and legal implications of artificial intelligence and other emerging technologies. My recent project (co-authored with Yoshua Bengio) examines how known results in deep learning may inform economic policy since machine-learning systems and economic entities (like corporations) are analogous---they are both adaptive, and their behaviour is specified in a more or less explicit way. Recent successes in deep learning suggest that a regulatory and fiscal environment which provides more implicit pressures on corporations may lead to their behaviour being more aligned with a collective human good.
</p>
   
<p>Outside of this central field of study, I have additional research interests in philosophy of language (more traditionally construed) and metasemantics; social and political philosophy; and 20th Century analytic philosophy—especially Frege, Russell, and Wittgenstein.</p>

<h2>Dissertation</h2>

<details>
   <summary><a> <strong> Complex Signals: Reflexivity, Hierarchical Structure, and Modular Composition </strong></a></summary>
   <div class="indented">
      <p>
         My dissertation argues that what drives the emergence of complex communication systems is a process of modular composition, whereby independent communicative dispositions combine to create more complex dispositions. This challenges the dominant view on the evolution of language, which attempts to resolve the explanatory gap between communication and language by demonstrating how complex syntax evolved. My research shows that these accounts fail to maintain sensitivity to empirical data: genuinely compositional syntax is extremely rare or non-existent in nature. In contrast, my research prioritises the reflexivity of natural language—the ability to use language to talk about language—as an alternative explanatory target. 
      </p>
      <p>
         The first part of my dissertation provides the philosophical foundation of this novel account using the theoretical framework of Lewis-Skyrms signalling games and drawing upon relevant work in evolutionary biology, linguistics, cognitive systems, and machine learning. Chapter 1 introduces the signalling game and contextualises it with respect to problems in the realm of traditional philosophy of language. Chapter 2 examines empirical data from biology and linguistics and argues that complex syntax is not the most apt explanatory target for how language might have evolved out of simple communication. Chapter 3 then argues that the reflexivity of language is a more fruitful property to consider, showing how reflexivity aids the evolution of complex communication via a process of modular composition. This connects parallel research in the evolution of language, cognitive systems, and machine learning paradigms. Once such complexity is exhibited, at a small scale, it may lead to a 'feedback loop' between communication and cognition that gives rise to the complexity we see in natural language.
      </p>
         The second part of my dissertation provides a set of models, along with analytic and simulation results, that show precisely how (and under what circumstances) this process of modular composition is supposed to work.
      </p>
      <p>
         Draft chapters are available upon request.<br>
      </p>
      <p>
         A more detailed summary of this work can be read <a href="https://travislacroix.github.io/files/ND-Dissertation-Summary.pdf" title="Dissertation Summary"> HERE.</a>
   </p>
   </div>
</details>

<h2>Published Articles</h2>

<details>
   <summary><a> <strong> The Dynamics of Retraction in Epistemic Networks </strong> (with Cailin O'Connor and Anders Geil) <br> <p style="text-indent: 20pt"><i>Philosophy of Science</i><p></a> </summary>
   <div class="indented">
      <p>
         Sometimes retracted scientific information is used and propagated long after it is understood to be misleading.  Likewise, sometimes retracted news items spread and persist, even after it has been publicly established that they are false.  In this paper, we use agent-based models of epistemic networks to explore the dynamics of retraction.  In particular we focus on why false beliefs might persist, even in the face of retraction.
      </p>
      <p>
         <a href="http://philsci-archive.pitt.edu/17088/" title="Dynamics of Retraction, Draft">[Unpublished Draft Available Here.]</a> (Please cite published version, if available.)<br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis, Anders Geil and Cailin O'Connor. (2020). "The Dynamics of Retraction in Epistemic Networks." <i>Philosophy of Science</i> (Accepted).<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Epistemology and the Structure of Language </strong> (with Jeffrey A. Barrett) <br> <p style="text-indent: 20pt"><i>Erkenntnis</i><p></a> </summary>

   </summary>
   <div class="indented">
      <p>
         We are concerned here with how structural properties of language may evolve to reflect features of the world in which it evolves. As a concrete example, we will consider how a simple term language might evolve to support the principle of indifference over state descriptions in that language. The point is not that one is justified in applying the principle of indifference to state descriptions in natural language. Rather, it is that one should expect a language that has evolved in the context of facilitating successful action to reflect probabilistic features of the world in which it evolved.
      <br> </p>
         <p>
         <a href="https://doi.org/10.1007/s10670-020-00225-4" title="Epistemology and the Structure of Language, Erkenntnis">[Official Version Available Here.]</a> <br>
      </p>
      <p>
         <a href="http://philsci-archive.pitt.edu/16844/" title="Epistemology and the Structure of Language, Pre-Print">[Pre-Print Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> Barrett, Jeffrey A. and Travis LaCroix. (2020). "Epistemology and the Structure of Language." <i>Erkenntnis</i> (Forthcoming).<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Communicative Bottlenecks Lead to Maximal Information Transfer </strong> <br> <p style="text-indent: 20pt"><i>Journal of Experimental and Theoretical Artificial Intelligence</i><p></a> </summary>

   </summary>
   <div class="indented">
      <p>
         This paper presents new analytic and numerical analysis of signalling games that give rise to informational bottlenecks—that is to say, signalling games with more state/act pairs than available signals to communicate information about the world. I show via simulation that agents learning to coordinate tend to favour partitions of nature which provide maximal information transfer. This is true in spite of the fact that nothing from an initial analysis of the stability properties of the underlying signalling game suggests that this should be the case. As a first pass to explain this, I note that the underlying structure of our model favours maximal information transfer in regard to the simple combinatorial properties of the ways in which the agents might partition nature into kinds. However, I suggest that this does not perfectly capture the empirical results; thus, several open questions remain.
      </p>
      <p>
         <a href="http://dx.doi.org/10.1080/0952813X.2020.1716857" title="Communicative Bottlenecks, Official">[Official Version Available Here.]</a>
      <br> </p>
         <p>
          <a href="http://philsci-archive.pitt.edu/16843/" title="Communicative Bottlenecks, Pre-Print">[Pre-Print Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br>LaCroix, Travis. (2020). "Communicative Bottlenecks Lead to Maximal Information Transfer." <i>Journal of Experimental and Theoretical Artificial Intelligence</i> (Forthcoming).<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Using Logic to Evolve More Logic: Composing Logical Operators via Self-Assembly </strong> <br> <p style="text-indent: 20pt"><i>British Journal for the Philosophy of Science</i><p></a> </summary>

   </summary>
   <div class="indented">
      <p>
         I consider how complex logical operations might self-assemble in a signalling-game context via composition of simpler underlying dispositions. On the one hand, agents may take advantage of pre-evolved dispositions; on the other hand, they may co-evolve dispositions as they simultaneously learn to combine them to display more complex behaviour. In either case, the evolution of complex logical operations can be more efficient that evolving such capacities from scratch. Showing how complex phenomena like these might evolve provides an additional path to the possibility of evolving more or less rich notions of compositionality. This helps provide another facet of the evolutionary story of how sufficiently rich, human-level cognitive or linguistic capacities may arise from simpler precursors.
         <br> </p>
         <p>
         <a href="https://doi.org/10.1093/bjps/axz049" title="Using Logic to Evolve More Logic, BJPS">[Official Version Available Here.]</a> <br>
      </p>
      <p>
         <a href="http://philsci-archive.pitt.edu/16658/" title="Using Logic to Evolve More Logic, Pre-Print">[Pre-Print Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. (2019). "Using Logic to Evolve More Logic: Composing Logical Operators via Self-Assembly." <i>British Journal for the Philosophy of Science</i>. Forthcoming. <br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Biology and Compositionality: Empirical Considerations for Emergent-Communication Protocols </strong> <br> <p style="text-indent: 20pt"><i>NeurIPS 2019 workshop Emergent Communication: Towards Natural Language</i><p></a> </summary>

   </summary>
   <div class="indented">
      <p>
         Significant advances have been made in artificial systems by using biological systems as a guide. However, there is often little interaction between computational models for emergent communication and biological models of the emergence of language. Many researchers in language origins and emergent communication take compositionality as their primary target for explaining how simple communication systems can become more like natural language. However, there is reason to think that compositionality is the wrong target on the biological side, and so too the wrong target on the machine-learning side. As such, the purpose of this paper is to explore this claim. This has theoretical implications for language origins research more generally, but the focus here will be the implications for research on emergent communication in computer science and machine learning—specifically regarding the types of programmes that might be expected to work and those which will not. I further suggest an alternative approach for future research which focuses on reflexivity, rather than compositionality, as a target for explaining how simple communication systems may become more like natural language. I end by providing some reference to the language origins literature that may be of some use to researchers in machine learning.
         <br> </p>
         <p>
         <a href="https://arxiv.org/abs/1911.11668" title="Biology and Compositionality, ArXiv">[Official Version Available Here.]</a> <br>
      </p>
      <p>
         <a href="http://travislacroix.github.io/files/LaCroix-NeurIPS-Poster-33x46-Biology-and-Compositionality.pdf" title="Biology and Compositionality, Poster">[Poster Available Here.]</a> <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. (2019). "Biology and Compositionality: Empirical Considerations for Emergent-Communication Protocols." <i>arxiv.org/abs/1911.11668</i>. <br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> Evolutionary Explanations of Simple Communication: Signalling Games &amp; Their Models </strong> <br> <p style="text-indent: 20pt"><i>Journal for General Philosophy of Science / Zeitschrift f&uuml;r allgemeine Wissenschaftstheorie</i><p></a> </summary>
   <div class="indented">
      <p>         
         This paper applies the theoretical criteria laid out by D'arms et al. (1998) to various aspects of evolutionary models of signalling. The question that D'Arms et al. seek to answer can be formulated as follows: Are the models that we use to explain the phenomena in question conceptually adequate? The conceptual adequacy question relates the formal aspects of the model to those aspects of the natural world that the model is supposed to capture. Moreover, this paper extends the analysis of D'Arms et al. by asking the following additional question: Are the models that we use sufficient to explain the phenomena in question? The sufficiency question ask what formal resources are minimally required in order for the model to get the right results most of the time.
      </p>
      <p>
         <a href="https://doi.org/10.1007/s10838-019-09481-7" title="Evolutionary Explanations of Simple Communication, JGPS">[Official Version Available Here.]</a><br>
      </p>
      <p>
         <a href="https://travislacroix.github.io/files/2019-10-29-Signalling-Games-and-Their-Models.pdf" title="Evolutionary Explanations of Simple Communication, Pre-Print">[Pre-Print Version Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. (2019). "Evolutionary Explanations of Simple Communication: Signalling Games &amp; Their Models." <i>Journal for General Philosophy of Science / Zeitschrift f&uuml;r allgemeine Wissenschaftstheorie</i>. (2020) 51(1): 19-43.<br>
      </p>
   </div>
</details>

<details>
   <summary><a> <strong> On Salience and Signalling in Sender-Receiver Games: Partial-Pooling, Learning, and Focal Points </strong> <br> <p style="text-indent: 20pt"><i>Synthese</i><p></a> </summary>
   <div class="indented">
      <p>
         I introduce an extension of the Lewis-Skyrms signaling game, analysed from a dynamical perspective via simple reinforcement learning. In Lewis' (Convention, Blackwell, Oxford, 1969) conception of a signaling game, salience is offered as an explanation for how individuals may come to agree upon a linguistic convention. Skyrms (Signals: evolution, learning & information, Oxford University Press, Oxford, 2010a) offers a dynamic explanation of how signaling conventions might arise presupposing no salience whatsoever. The extension of the atomic signaling game examined here—which I refer to as a <i>salience game</i>—introduces a variable parameter into the atomic signaling game which allows for degrees of salience, thus filling in the continuum between Skyrms' and Lewis' models. The model does not presuppose any salience at the outset, but illustrates a process by which accidentally evolved salience is amplified, to the benefit of the players. It is shown that increasing degrees of salience allow populations to avoid sub-optimal pooling equilibria and to coordinate upon conventions more quickly. <br>
      </p>
      <p>
         <a href="https://doi.org/10.1007/s11229-018-1766-z" title="Salience and Signaling, Synthese">[Official Version Available Here.]</a><br>
      </p>
      <p>
         <a href="https://travislacroix.github.io/files/2018-03-20-Salience-and-Signalling.pdf" title="Salience and Signaling, Pre-Print">[Pre-Print Version Available Here.]</a> (Please cite official version.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. (2018). "On Salience and Signaling in Sender-Receiver Games: Partial Pooling, Learning, and Focal Points." <i>Synthese</i>. (2020) 197(4): 1725-1747. <br>
      </p>
      </div>
</details>

<h2>Under Review</h2>

<details>
   <summary><a> <strong> Accounting for Polysemy and Role Asymmetry in the Evolution of Compositional Signals </strong></a> </summary>
   <div class="indented">
      <p>
         Several formal models of signalling conventions have been proposed to explain how and under what circumstances compositional signalling might evolve. I suggest that these models fail to give a plausible account of the evolution of compositionality because (1) they apparently take <i>linguistic</i> compositionality as their target phenomenon, and (2) they are insensitive to role asymmetries inherent to the signalling game. I further suggest that, rather than asking how signals might come to be compositional, we must clarify what it would mean for signals to <i>be</i> compositional to begin with.
 <br>
      </p>
      <p>
         <a href="https://travislacroix.github.io/files/ND-Polysemy-and-Role-Asymmetry.pdf" title="Polysemy and Role Asymmetry, Draft">[Unpublished Draft Available Here.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. (2019). "Accounting for Polysemy and Role-Asymmetry in the Evolution of Compositional Signals." <i>Unpublished Manuscript</i>. May 2019, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> The Correction Game or, How Pre-Evolved Communicative Dispositions Might Affect Communicative Dispositions </strong></a> </summary>
   <div class="indented">
      <p>
         How might pre-evolved communicative dispositions affect how individuals learn to communicate in a novel context? I present a model of learning that varies the reward for coordination in the signalling game framework under simple reinforcement learning as a function of the agents' actions. The model takes advantage of a type of modular compositional communicative bootstrapping by which the sender and receiver use pre-evolved communicative dispositions—a "yes/no" command—to evolve new dispositions.
 <br>
      </p>
      <p>
         <a href="https://travislacroix.github.io/files/ND-Correction-Game.pdf" title="Correction Game, Draft">[Unpublished Draft Available Here.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. (2019). "The Correction Game or, How Pre-Evolved Communicative Dispositions Might Affect Communicative Dispositions." <i>Unpublished Manuscript</i>. April 2019, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> Learning From Learning Machines: Optimisation, Rules, and Social Norms </strong> (with Yoshua Bengio) </a> </summary>
   <div class="indented">
      <p>
         There is an analogy between machine learning systems and economic entities in that they are both adaptive, and their behaviour is specified in a more or less explicit way. It appears that the area of AI that is most analogous to the behaviour of economic entities is that of <i>morally good decision-making</i>, but it is an open question as to how precisely moral behaviour can be achieved in an AI system. This paper explores the analogy between these two complex systems, and we suggest that a clearer understanding of this apparent analogy may help us forward in both the socio-economic domain and the AI domain: known results in economics may help inform feasible solutions in AI safety, but also known results in AI may inform economic policy. If this claim is correct, then the recent successes of deep learning for AI suggest that more <i>implicit</i> specifications work better than explicit ones for solving such problems. 
      </p>
      <p>
         <a href="https://arxiv.org/abs/2001.00006" title="Learning from Learning Machines, Draft">[Unpublished Draft Available Here.]</a> (Please cite published version, if available.)<br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis and Yoshua Bengio. (2019). "Learning from Learning Machines: Optimisation, Rules, and Social Norms." Unpublished.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> Power by Association </strong> (with Cailin O'Connor) </a> </summary>
   <div class="indented">
      <p>
         We use tools from evolutionary game theory to examine how power might influence the cultural evolution of inequitable norms between discernible groups (such as gender or racial groups) in a population of otherwise identical individuals. Similar extant models always assume that power is homogeneous across a social group. As such, these models fail to capture situations where individuals who are not themselves disempowered nonetheless end up disadvantaged in bargaining scenarios by dint of their social group membership. Thus, we assume that there is heterogeneity in the groups in that some individuals are more powerful than others.
      </p>
      <p>
         Our model shows that even when most individuals in two discernible sub-groups are relevantly identical, powerful individuals can affect the social outcomes for their entire group; this results in power by association for their in-group and a bargaining disadvantage for their out-group. In addition, we observe scenarios like those described where individuals who are more powerful will get less in a bargaining scenario because a convention has emerged disadvantaging their social group.
      </p>
      <p>
         <a href="http://philsci-archive.pitt.edu/14318/" title="Power by Association, Draft">[Unpublished Draft Available Here.]</a> (Please cite published version, if available.)<br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis and Cailin O'Connor. (2018). "Power by Association." <i>Unpublished Manuscript</i>. January 2018, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> Emergent Communication under Competition </strong> (with Michael Noukhovitch and Aaron Courville) </a> </summary>
   <div class="indented">
      <p>
         Current literature in machine learning states that competitive agents do not naturally learn to use an emergent communication channel. We introduce a modified sender-receiver game to study the spectrum of partially-competitive scenarios and show communication can indeed emerge naturally. We empirically demonstrate three key takeaways for future research. First, we show that communication is proportional to cooperation, and it naturally occurs for situations that are more cooperative than competitive. Second, we highlight the difference between communication and manipulation and extend previous metrics of communication to the competitive case. Third, we investigate the negotiation game of Cao et al. (2018) and show that, in this setting, both agents must benefit from communication for it to emerge.
      </p>
            <p>
         <b>Recommended citation</b>: <br>Noukhovitch, Michael, Travis LaCroix, Angeliki Lazaridou, and Aaron Courville. (2018). "Emergent Communication under Competition." <i>Unpublished Manuscript</i>. June 2020, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong>Reflexivity, Functional Reference, and Modularity: Alternative Targets for Language Origins</strong></a> </summary>
   <div class="indented">
      <p>
         Researchers in language origins typically try to explain how compositional communication might evolve to bridge the gap between animal communication and natural language. However, as an explanatory target, compositionality has been shown to be problematic for a gradualist approach to the evolution of language.  In this paper, I suggest that <i>reflexivity</i> provides an apt and plausible alternative target which does not succumb to the problems that compositionality faces. I further explain how <i>proto</i>-reflexivity, which depends upon functional reference, gives rise to complex communication systems via modular composition.
      <p>
         <a href="https://travislacroix.github.io/files/ND-Reflexivity-Functional-Reference-Modularity.pdf" title="Reflexivity, Functional Reference, and Modularity">[Unpublished Draft Available Here.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. (2020). "Reflexivity, Functional Reference, and Modularity: Alternative Targets for Language Origins." <i>Unpublished Manuscript</i>. June 2020, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> The Tragedy of the AI Commons </strong> (with Aydin Mohseni) </a> </summary>
   <div class="indented">
      <p>
         Policy and guideline proposals for ethical artificial-intelligence research have proliferated in recent years. These are supposed to guide the socially-responsible development of AI for the common good. However, there typically exist incentives for non-cooperation (i.e., non-adherence to such policies and guidelines); and, these proposals often lack effective mechanisms to enforce their own normative claims. The situation just described constitutes a social dilemma—namely, a situation where no one has an individual incentive to cooperate, though mutual cooperation would lead to the best outcome for all involved. In this paper, we use stochastic evolutionary game dynamics to model this social dilemma in the context of the ethical development of artificial intelligence. This formalism allows us to isolate variables that may be intervened upon, thus providing actionable suggestions for increased cooperation amongst numerous stakeholders in AI. Our results show how stochastic effects can help make cooperation viable in such a scenario. They suggest that coordination for a common good should be attempted in smaller groups in which the cost for cooperation is low, and the perceived risk of failure is high. This provides insight into the conditions under which we should expect such ethics proposals to be successful with regard to their scope, scale, and content.
 <br>
      </p>
      <p>
         <a href="https://arxiv.org/abs/2006.05203" title="Tragedy of the AI Commons, Draft">[arXiv Pre-Print.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis and Aydin Mohseni. (2020). "The Tragedy of the AI Commons." <i>Unpublished Manuscript</i>. June 2020, PDF File.<br>
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> What Russell Can Denote: Aboutness and Denotation Between <i>Principles</i> and 'On Denoting' </strong></a> </summary>
   <div class="indented">
      <p>
         How ought we to analyse propositions that are about nonexistent entities? Russell (1903) details the concept of <i>denoting</i> in <i>Principles of Mathematics</i>, and this theory appears to answer the question posed. However, in the paper 'On Denoting' (Russell 1905), we see that his theory of denoting has changed greatly. Hylton (1990) argues that the move from the former theory to the latter was unnecessary. The purpose of this paper is to show that, contra Hylton, the move to the theory found in 'On Denoting' was indeed necessary.</p>
         <p>I argue that Hylton is correct to the extent that an answer to our first question relies on a different question concerning the ontology of nonexistent entities. However, this fails to take into account is a more interesting question regarding the truth values of propositions containing such puzzling entities. This question relies on Russell's notion of aboutness, and in this sense is more sensitive to his theory as a complete picture of denotation. If we take the aboutness relation seriously, then we see that the move from the former theory to the latter was necessary after all.<br>
      </p>
      <p>
         <a href="https://travislacroix.github.io/files/ND-What-Russell-Can-Denote.pdf" title="What Russell Can Denote, Draft">[Unpublished Draft Available Here.]</a> (Please cite official version, if available.) <br>
      </p>
      <p>
         <b>Recommended citation</b>: <br> LaCroix, Travis. (2019). "What Russell Can Denote: Aboutness and Denotation Between <i>Principles</i> and 'On Denoting'." <i>Unpublished Manuscript</i>. May 2019, PDF File.<br>
      </p>
   </div>
</details>

<h2>Selected Working Papers</h2>

<details>
   <summary><a> <strong> Reference by Proxy and Truth-in-a-Model </strong> </a> </summary>
   <div class="indented">
      <p>
         Simchen (2017) brings to light the notion of 'scrambled truth' to show how productivist metasemantics is able to deal with problems of singular reference in a way that an interpretationist metasemantics (such as Lewisian reference magnetism) cannot. This serves to show that productivism is a live alternative, and indeed a rival to interpretationist metasemantics, and so cannot be subsumed by interpretationist theories.
      </p>
      <p>
         I examine Simchen's challenge to interpretationist metasemantics by extending his theoretical problem in light of actual communicative exchanges. I show that when the problem is couched in these terms, the ability to refer depends inherently upon coordination—the onus of which is on the receiver. Thus, I show how the interpretationist stance, in this case, can reasonably be understood to encompass the productivist stance.
      </p>
   </div>
</details>

<br>

<details>
   <summary><a> <strong> Saltationist versus Gradualist Approaches to Language Origins: A Critical Discussion </strong> </a> </summary>
   <div class="indented">
      <p>
         In spite of their vast differences, theories of language origins can be, more or less, partitioned into two exhaustive and mutually exclusive camps: <i>saltationist</i> and <i>gradualist</i>. Saltationism—from the Latin <i>saltus</i>, meaning 'leap'—is the view that (the human-level capacity for) language sprang into existence suddenly and recently, and that there is a complete discontinuity between the linguistic capacities of humans and the communication systems of non-human animals; whereas, gradualism—from the Latin <i>gradus</i>, meaning 'step'—is the view that language evolved slowly over long periods of time. However, rather than arguing for the plausibility of a gradualist versus a saltationist scenario, most researchers appear to fall into one or the other camp based purely upon external or pre-theoretic commitments regarding what they believe evolved [emerged] and how.
      </p>
      <p>
         The purpose of this paper is to critically survey the respective commitments and entailments of saltationist and gradualist theories of language origins in order to make an explicit argument that the saltationist view is theoretically untenable. Under scrutiny, holding one or the other theoretical stance toward language origins will require or entail certain commitments, which vary in plausibility. It appears that many researchers either ignore these facts or are willing to bite the bullet with respect to them. However, arguments for why one should be so willing are often few and far between.
      </p>
   </div>
</details>

<br>


