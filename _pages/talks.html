---
layout: archive
title: "Talks and Presentations"
permalink: /talks/
author_profile: true
---

<style> .indented { padding-left: 50pt; padding-right: 50pt; } </style>

<details>
   <summary><a> <strong> Moral Machines and Moral Dilemmas </strong></a> </summary>
   <div class="indented">
      <p>
             Autonomous systems are being developed and deployed in situations that may require some degree of ethical decision-making ability. As a result, research in machine ethics has proliferated in recent years. Part of this work has involved the use of moral dilemmas as validation mechanisms for the implementation of algorithms for decision making in ethically-loaded situations. Using trolley-style problems in the context of autonomous vehicles as a case study, I argue (1) that this is a misapplication of philosophical thought experiments because (2) it fails to appreciate the purpose of moral dilemmas, and (3) this has potentially catastrophic consequences; however, (4) there are uses of moral dilemmas in machine ethics that are appropriate and the novel situations that arise in a machine-learning context can shed some light on philosophical work in ethics.
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li><strike>American Philosophical Association, Eastern Division. Baltimore, USA. Jan. 2022.</strike> [Withdrawn]</li>
   </ul>

<details>
   <summary><a> <strong> The Tragedy of the AI Commons </strong></a> </summary>
   <div class="indented">
      <p>
             Policy and guideline proposals for ethical artificial-intelligence research have proliferated in recent years. These are supposed to guide the socially-responsible development of AI for the common good. However, there typically exist incentives for non-cooperation (i.e., non-adherence to such policies and guidelines); and, these proposals often lack effective mechanisms to enforce their own normative claims. The situation just described constitutes a social dilemma---namely, a situation where no one has an individual incentive to cooperate, though mutual cooperation would lead to the best outcome for all involved. In this paper, we use stochastic evolutionary game dynamics to model this social dilemma in the context of the ethical development of artificial intelligence. This formalism allows us to isolate variables that may be intervened upon, thus providing actionable suggestions for increased cooperation amongst numerous stakeholders in AI. Our results show how stochastic effects can help make cooperation viable in such a scenario. They suggest that coordination for a common good should be attempted in smaller groups in which the cost for cooperation is low, and the perceived risk of failure is high. This provides insight into the conditions under which we should expect such ethics proposals to be successful with regard to their scope, scale, and content.
      </p>
      <p>A recording of this talk is available <a href="https://player.vimeo.com/video/505335066?h=4403910eed"><strong>here</strong></a>.
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li><i>Poster Session</i>, Philosophy of Science Association. Baltimore, USA. Nov. 2021.</li>
      <li><i>Virtual Poster Session</i>, Philosophy of Science Association. Online. Jan. 2021.</li>
      <li><i>Invited Talk</i>, Schwartz Reisman Institute for Technology and Society. Toronto, Canada. (Online). Jan. 2021.</li>
   </ul>

<details>
   <summary><a> <strong> Reflexivity, Functional Reference, and Modularity: Alternative Targets for Language Origins </strong></a> </summary>
   <div class="indented">
      <p>
             Researchers in language origins typically try to explain how compositional communication might evolve to bridge the gap between animal communication and natural language. However, as an explanatory target, compositionality has been shown to be problematic for a gradualist approach to the evolution of language. In this paper, I suggest that <i>reflexivity</i> provides an apt and plausible alternative target which does not succumb to the problems that compositionality faces. I further explain how <i>proto</i>-reflexivity, which depends upon functional reference, gives rise to complex communication systems via modular composition. 
      </p>
      <p> The paper associated with this talk has been accepted for publication in <i>Philosophy of Science</i>. A pre-print can be found on the PhilSci archive, <a href="http://philsci-archive.pitt.edu/17441/" title="Reflexivity, Functional Reference, and Modularity, Pre-Print">here</a>.
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>Philosophy of Science Association. Baltimore, USA. Nov. 2021.</li>
   </ul>

<details>
   <summary><a> <strong> If Gradualism Is the Correct Approach to Language Origins, Then Compositionality Is Not a Plausible Explanatory Target </strong></a> </summary>
   <div class="indented">
      <p>
             In this paper, I suggest that if the gradualist approach to language origins is correct, then compositionality is the wrong explanatory target for filling the explanatory gap between simple communication systems (as found in nature) and linguistic communication systems (i.e., natural languages).
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li><strike>Canadian Philosophical Association. London, Canada. Jun. 2020.</strike> [Cancelled due to COVID-19]</li>
   </ul>

<details>
   <summary><a> <strong> Learning from Learning Machines: Optimisation, Rules, and Social Norms </strong></a> </summary>
      <p>
         (w/ Y. Bengio)
      </p>
   <div class="indented">
      <p>
             There is an analogy between machine learning systems and economic entities in that they are both adaptive, and their behaviour is specified in a more or less explicit way. It appears that the area of AI that is most analogous to the behaviour of economic entities is that of <i>morally good decision-making</i>, but it is an open question as to how precisely moral behaviour can be achieved in an AI system. This paper explores the analogy between these two complex systems, and we suggest that a clearer understanding of this apparent analogy may help us forward in both the socio-economic domain and the AI domain: known results in economics may help inform feasible solutions in AI safety, but also known results in AI may inform economic policy. If this claim is correct, then the recent successes of deep learning for AI suggest that more <i>implicit</i> specifications work better than explicit ones for solving such problems. 
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li><strike>Canadian Society for the History and Philosophy of Science (CSHPS/SCHPS). London, ON. May 2020.</strike> [Cancelled due to COVID-19]</li>
      <li><strike>Society for the study of Artificial Intelligence and Simulation of Behaviour. London, UK. April 2020.</strike> [Cancelled due to COVID-19]</li>
      <li>Canadian Society for Epistemology. Montr√©al, QC. Nov. 2019.</li>
   </ul>

<details>
   <summary><a> <strong> Emerging Communication Under Conflict of Interest </strong> (Co-Presented with Michael Noukhovitch)</a> </summary>
            <p>
         (w/ M. Noukhovitch, A. Lazaridou, A. Courville)
      </p>
   <div class="indented">
      <p>
             Current literature in machine learning holds that when their interests are not aligned, agents do not learn to use an emergent communication channel. We introduce a new sender-receiver game to study emergent communication for this spectrum of partially-competitive scenarios and put special care into evaluation. We find that communication can indeed emerge in partially-competitive scenarios, and we discover three things that are tied to improving it. First, that communication under partial conflict of interest is proportional to cooperation, and it naturally occurs for situations that are more cooperative than competitive. Second, that stability and performance are improved by using LOLA (Foerster et al, 2018), especially in more competitive scenarios. And third, that discrete protocols lend themselves better to learning cooperative communication than continuous ones.
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li><strike>EvoLang XII. Brussels, Belgium. 14-17 Apr. 2020.</strike> [Cancelled due to COVID-19]</li>
   </ul>

<details>
   <summary><a> <strong> Epistemology and the Structure of Language </strong></a> </summary>
      <p>
         (w/ J. A. Barrett)
      </p>
   <div class="indented">
      <p>
             We are concerned here with how structural properties of language may come to reflect features of the world in which it evolves. As a concrete example, we will consider how a simple term language might evolve to support the principle of indifference over state descriptions in that language. The point is not that one is justified in applying the principle of indifference to state descriptions in natural language. Instead, it is that one should expect a language that has evolved in the context of facilitating successful action to reflect probabilistic features of the world in which it evolved. 
      </p>
            <p> The paper associated with this talk has been accepted for publication in <i>Erkenntnis</i>. A pre-print can be found on the PhilSci archive, <a href="http://philsci-archive.pitt.edu/16986/" title="Epistemology and the Structure of Language, Pre-Print">here</a>.

   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li> Concordia Research Symposium in Philosophy. Montr&eacute;al, QC. Feb. 2020.</li>
   </ul>

<details>
   <summary><a> <strong> Biology and Compositionality: Considerations for Emergent-Communication Protocols </strong></a> </summary>
   <div class="indented">
      <p>
             Significant advances have been made in artificial systems by using biological systems as a guide. However, there is often little interaction between computational models for emergent communication and biological models of the emergence of language. Many researchers in language origins and emergent communication take compositionality as their primary target for explaining how simple communication systems can become more like natural language. However, there is reason to think that compositionality is the wrong target on the biological side, and so too the wrong target on the machine-learning side. As such, the purpose of this paper is to explore this claim. This has theoretical implications for language origins research more generally, but the focus here will be the implications for research on emergent communication in computer science and machine learning‚Äîspecifically regarding the types of programmes that might be expected to work and those which will not. I further suggest an alternative approach for future research which focuses on reflexivity, rather than compositionality, as a target for explaining how simple communication systems may become more like natural language. I end by providing some reference to the language origins literature that may be of some use to researchers in machine learning.
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>Emergent Communication Workshop at the 33rd Conference on Neural Information Processing Systems (NeurIPS 2019). Vancouver, BC. Dec. 2019.</li>
   </ul>

<details>
   <summary><a> <strong> Using Logic to Evolve More Logic: Composing Logical Operators via Self-Assembly </strong></a> </summary>
   <div class="indented">
      <p>
         In recent work on self-assembly, Barrett and Skyrms (2017) show how a binary logical operator can evolve more quickly in a signalling game when the agents utilize pre-evolved dispositions-as opposed to learning a new disposition from scratch-via template transfer. Their argument is not intended to show how such logical dispositions might evolve in the first place. Further, template transfer does not show how to evolve, e.g., a ternary-input logical operator from a binary-input logical operator. This paper extends their analysis. I begin by analysing simple unary logical operations, rather than binary ones. I then show how binary logical operations can evolve out of unary logical operations via modular composition-a process whereby one game evolves to accept the play of another game as input. Thus, the new models presented here are able to account for phenomena which cannot be accommodated by the models presented in Barrett and Skyrms (2017).
      </p>
      <p> The paper associated with this talk has been accepted for publication in <i>British Journal for the Philosophy of Science</i>. A pre-print can be found on the PhilSci archive, <a href="http://philsci-archive.pitt.edu/16658/" title="Using Logic to Evolve More Logic, Pre-Print">here</a>.

   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li><strike>Congress for Logic, Methodology, and Philosophy of Science and Technology. Prague, Czechia. August 2019.</strike> (Unable to attend)</li>
      <li>Society for Exact Philosophy. Toronto, ON. May 2019.</li>
      <li>American Philosophical Association, Pacific Division. Vancouver, BC. April 2019.</li>
   </ul>

<details>
   <summary><a> <strong> The Correction Game </strong></a> </summary>
   <div class="indented">
      <p>
         How might pre-evolved communicative dispositions affect how individuals learn to communicate in a novel context? I present a model of learning that varies the reward for coordination in the signalling-game framework under simple reinforcement learning as a function of the agents' actions. The model takes advantage of a type of modular compositional communicative bootstrapping by which the sender and receiver use pre-evolved communicative dispositions‚Äîa "yes/no" command‚Äîto evolve new dispositions.      
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li><strike>Formal Epistemology Workshop. Turin, Italy. June 2019.</strike> (Unable to attend)</li>
   </ul>

<details>
   <summary><a> <strong> Less Is More: Degrees of Compositionality for Complex Signals </strong></a> </summary>
   <div class="indented">
      <p>
         Several formal models of signalling conventions have been proposed to explain how and under what circumstances compositional signalling might evolve. I suggest that these models fail to give a plausible account of the evolution of compositionality because (1) they apparently take <i>linguistic</i> compositionality as their target phenomenon, and (2) they are insensitive to role asymmetries inherent to the signalling game. I further suggest that, rather than asking how signals might come to be compositional, we must clarify what it would mean for signals to be compositional to begin with. 
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>Philosophy of Science Association. Seattle, USA. November 2018.</li>
   </ul>

<details>
   <summary><a> <strong> Reference by Proxy and Truth-in-a-Model </strong></a> </summary>
   <div class="indented">
      <p>
         I examine Simchen's (2017) challenge to interpretationist metasemantics by extending his theoretical problem of singular reference in light of actual communicative exchanges. I show that when the problem is couched in these terms, the ability to refer depends inherently upon coordination‚Äîthe onus of which is on the receiver. Thus, I show how the interpretationist stance, in this case, can reasonably be understood to encompass the productivist stance. 
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>Western Canadian Philosophical Association. Calgary, AB. October 2018.</li>
   </ul>

<details>
   <summary><a> <strong> On the Role of Power in the Evolution of Inequitable Norms </strong></a> </summary>
      <p>
         (w/ C. O'Connor)
      </p>
   <div class="indented">
      <p>
         We use tools from evolutionary game theory to examine how power might influence the cultural evolution of inequitable norms between discernible groups (such as gender or racial groups) in a population of otherwise identical individuals. Similar extant models always assume that power is homogeneous across a social group. As such, these models fail to capture situations where individuals who are not themselves disempowered nonetheless end up disadvantaged in bargaining scenarios by dint of their social group membership. Thus, we assume that there is heterogeneity in the groups in that some individuals are more powerful than others.
      </p>
      <p>                                     
         Our model shows that even when most individuals in two discernible sub-groups are relevantly identical, powerful individuals can affect the social outcomes for their entire group; this results in power by association for their in-group and a bargaining disadvantage for their out-group. In addition, we observe scenarios like those described where individuals who are more powerful will get less in a bargaining scenario because a convention has emerged disadvantaging their social group.
      </p>
   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>Canadian Philosophical Association. Montr&eacute;al, QC. June 2018.</li>
      <li>Philogica V &amp; ALFAn V. Villa de Leyva, Colombia. May 2018.</li>
   </ul>

<details>
   <summary><a> <strong> On The Role of Information in the Evolution of Signalling </strong></a> </summary>
   <div class="indented">
      <p>
          I present new analytic and numerical analyses of signalling games that give rise to informational bottlenecks‚Äîthat is to say, signalling games with more state/act pairs than available signals to communicate information about the world. I show that agents learning to coordinate tend to favour maximal information transfer in spite of the fact that nothing from an initial analysis of the stability properties of the underlying signalling game suggests that this should be the case. To explain this, I note that the underlying structure of this model favours maximal information transfer in regard to the simple combinatorial properties of the ways in which the agents might partition nature into kinds.                        
      </p>
      <p> The paper associated with this talk has been accepted for publication in <i>Journal for Experimental and Theoretical Artificial Intelligence</i>. A pre-print can be found on the PhilSci archive, <a href="http://philsci-archive.pitt.edu/16843/" title="Communicative Bottlenecks, Pre-Print">here</a>.

   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>University of Calgary Graduate Philosophy Conference. Calgary, AB. May 2018.</li>
   </ul>
                                                    
<details>
   <summary><a> <strong> On Salience and Signalling in Sender-Receiver Games </strong></a> </summary>
   <div class="indented">
      <p>
      I introduce an extension of the Lewis-Skyrms signalling game, analysed from a dynamical perspective via simple reinforcement learning. In Lewis' (1969) conception of a signalling game, salience is offered as an explanation for how individuals may come to agree upon a linguistic convention. Skyrms (2010) offers a dynamic explanation of how signalling conventions might arise presupposing no salience whatsoever. The extension of the atomic signalling game examined here‚Äîwhich I refer to as a <i>salience game</i>‚Äîintroduces a variable parameter into the atomic signalling game which allows for degrees of salience, thus filling in the continuum between Skyrms' and Lewis' models. The model does not presuppose any salience at the outset, but illustrates a process by which accidentally evolved salience is amplified, to the benefit of the players. It is shown that increasing degrees of salience allow populations to avoid sub-optimal pooling equilibria and to coordinate upon conventions more quickly.
      </p>
      <p> The paper associated with this talk has been accepted for publication in <i>Synthese</i>. A pre-print can be found on the PhilSci archive, <a href="http://philsci-archive.pitt.edu/16270/" title="Salience and Signalling, Pre-Print">here</a>.

   </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>Western Canadian Philosophical Association. Regina, SK. October 2017.</li>
      <li>Luce Graduate Student Conference. Irvine, USA. June 2017.</li>
   </ul>

<details>
   <summary><a> <strong> Signalling Games &amp; Their Models </strong></a> </summary>
      <div class="indented">
         <p>         
            I apply the theoretical criteria laid out by D'Arms, et al. (1998) to various aspects of evolutionary models of signalling (Skyrms 2010). The question that D'Arms, et al. seek to answer can be formulated as follows: Are the models that we use to explain the phenomena in question conceptually adequate? The conceptual adequacy question relates the formal aspects of the model to those aspects of the natural world that are supposed to be captured by the model. Moreover, this paper extends the analysis of D'Arms, et al. by asking the following additional question: Are the models that we use sufficient to explain the phenomena in question? The sufficiency question asks what formal resources are minimally required in order for the model to get the right results most of the time.
         </p>
         <p> The paper associated with this talk has been accepted for publication in <i>Journal for General Philosophy of Science</i>. A pre-print can be found on the PhilSci archive, <a href="http://philsci-archive.pitt.edu/16604/" title="Salience and Signalling, Pre-Print">here</a>.

      </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>Philogica IV: Colombian Conference on Logic, Epistemology, &amp; Philosophy of Science. Bogota, Colombia. February 2016.</li>
   </ul>

<details>
   <summary><a> <strong> Fractionally Quantified Predicate Logic </strong></a> </summary>
      <div class="indented">
         <p>
            The notion of fractional quantification‚Äîquantified statements of the form 'at least half of A are B'‚Äîarises in the context of Aristotle‚Äôs Syllogistic. Several different models have been proposed to formalize syllogistic logic‚Äîthe most complete of which, perhaps, in which the syllogistic is extended to include denumerably many quantifiers (Johnson 1994). However, the notion of fractional quantification seems to arise only in the context of Aristotle‚Äôs syllogistic. The question that is raised here is simply, '<i>Why</i>?' 
                           </p>
                           <p>
                           In order to answer this question, the purpose of this paper is to adequately formulate the motivation for the question of whether it is possible to construct a (non-Aristotelian) formal system supplemented with fractional quantification. This will be assesed in two sections: first, antecedent problems with classical quantification that would make such a model desirable; second, (forseeable) initial problems that may arise as a consequence of such a construction, to the extent that it is possible.                  
      </p>
        
      </div>
</details>
   <ul style="list-style-type:none; font-size:15px">
      <li>Logic, Math and Physics Graduate Student Conference. London, ON. June 2015.</li>
   </ul>
